{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQxHk6mB1vqkzvQXlxCT2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dooooing/2023-ESAA-/blob/main/%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C_%EC%BD%94%EB%93%9C_%EA%B3%B5%EC%9C%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LGBM"
      ],
      "metadata": {
        "id": "vgkvDMOF2XvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. LIBRARY 불러오기"
      ],
      "metadata": {
        "id": "YvoX80o_0kAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "7iS-INuLtqib"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 전처리"
      ],
      "metadata": {
        "id": "U0WifUDD0nn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "5rdwPcsn0uu2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "KriYXV9r40xX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "index 칼럼 삭제"
      ],
      "metadata": {
        "id": "W8sxaHpS1DYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(['index'], axis=1)\n",
        "test = test.drop(['index'], axis=1)"
      ],
      "metadata": {
        "id": "lBqD8rY51G7p"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "missing value는 'NAN' 문자열로 대체"
      ],
      "metadata": {
        "id": "o-AKOBHF0s72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.fillna('NAN', inplace=True)\n",
        "test.fillna('NAN', inplace=True)"
      ],
      "metadata": {
        "id": "jJ3srf-w0peH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "object(문자열) onehot encoding"
      ],
      "metadata": {
        "id": "Cf9KqW7t1qom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object_col = []\n",
        "for col in train.columns:\n",
        "    if train[col].dtype == 'object':\n",
        "        object_col.append(col)"
      ],
      "metadata": {
        "id": "QvizxBTl1yC2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder()\n",
        "enc.fit(train.loc[:,object_col])\n",
        "\n",
        "\n",
        "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(),\n",
        "             columns=enc.get_feature_names_out(object_col))\n",
        "train.drop(object_col, axis=1, inplace=True)\n",
        "train = pd.concat([train, train_onehot_df], axis=1)"
      ],
      "metadata": {
        "id": "oj8aqL-810GI"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(),\n",
        "             columns=enc.get_feature_names_out(object_col))\n",
        "test.drop(object_col, axis=1, inplace=True)\n",
        "test = pd.concat([test, test_onehot_df], axis=1)"
      ],
      "metadata": {
        "id": "1DP_SWA_12jv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 모델링"
      ],
      "metadata": {
        "id": "20JlB3b02A5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stratifiedKFold를 사용해 y값 분포를 비슷하게 분리"
      ],
      "metadata": {
        "id": "M8DW2Lh52K8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
        "    folds.append((train_idx, valid_idx))"
      ],
      "metadata": {
        "id": "a0qF0aap2J3r"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "lgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n",
        "    lgb = LGBMClassifier(n_estimators=1000)\n",
        "    lgb.fit(X_train, y_train, eval_metric='logloss', eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
        "    lgb_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAFzIgSY2U6a",
        "outputId": "a022bab4-61de-4032-f3e3-bb5b89810c44"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================1============================================\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004044 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 813\n",
            "[LightGBM] [Info] Number of data points in the train set: 21165, number of used features: 53\n",
            "[LightGBM] [Info] Start training from score -2.105723\n",
            "[LightGBM] [Info] Start training from score -1.440314\n",
            "[LightGBM] [Info] Start training from score -0.444119\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================2============================================\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012250 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 819\n",
            "[LightGBM] [Info] Number of data points in the train set: 21165, number of used features: 53\n",
            "[LightGBM] [Info] Start training from score -2.105723\n",
            "[LightGBM] [Info] Start training from score -1.440314\n",
            "[LightGBM] [Info] Start training from score -0.444119\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================3============================================\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005122 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 819\n",
            "[LightGBM] [Info] Number of data points in the train set: 21166, number of used features: 53\n",
            "[LightGBM] [Info] Start training from score -2.105382\n",
            "[LightGBM] [Info] Start training from score -1.440162\n",
            "[LightGBM] [Info] Start training from score -0.444240\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================4============================================\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003623 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 815\n",
            "[LightGBM] [Info] Number of data points in the train set: 21166, number of used features: 53\n",
            "[LightGBM] [Info] Start training from score -2.105382\n",
            "[LightGBM] [Info] Start training from score -1.440162\n",
            "[LightGBM] [Info] Start training from score -0.444240\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================5============================================\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003493 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 819\n",
            "[LightGBM] [Info] Number of data points in the train set: 21166, number of used features: 53\n",
            "[LightGBM] [Info] Start training from score -2.105382\n",
            "[LightGBM] [Info] Start training from score -1.440162\n",
            "[LightGBM] [Info] Start training from score -0.444240\n",
            "================================================================================\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.iloc[:,1:]=0\n",
        "for fold in range(5):\n",
        "    submit.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5"
      ],
      "metadata": {
        "id": "iRuGU8Ii_zJF"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('submit_lgbm.csv', index=False)"
      ],
      "metadata": {
        "id": "bSaBqIun_zvF"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomforest"
      ],
      "metadata": {
        "id": "hOWyBORSAq5V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2s2Z0LV_5Lm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}